{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to locally run parallel code with mpi4py in an IPython notebook:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prerequisite for this is a working installation of some MPI distribution.\n",
    "\n",
    "Using Ubuntu or some derivative, I recommend using OpenMPI which can be istalled from the repository by means of the following packages: *libopenmpi-dev, openmpi-bin, openmpi-doc*.\n",
    "\n",
    "Now, you can already run MPI enabled code from you shell by calling\n",
    "\n",
    "*$mpirun -n [numbmer_of_threads] python [script_to_run.py]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use MPI with iPython, one has to install ipyparallel:\n",
    "\n",
    "via pip: *$pip install ipyparallel*\n",
    "\n",
    "via conda: *$conda install ipyparallel*\n",
    "\n",
    "and then enable the Clusters tab in ipython via\n",
    "\n",
    "*$ ipcluster nbextension enable*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make MPI acessable via mpi4py in an ipython notebook, one has to do the following:\n",
    "open one shell and start the ipcontroller:\n",
    "\n",
    "*$ipcontroller*\n",
    "\n",
    "open another shell and start a number of engines:\n",
    "\n",
    "*$mpirun-n [number of engines] ipengine --mpi=mpi4py*\n",
    "\n",
    "and then connect to the engines via the following fragment of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] /home/jakob/ownCloud/Documents/PhD/Tools/pymofa/tutorial\n",
      "[stdout:1] /home/jakob/ownCloud/Documents/PhD/Tools/pymofa/tutorial\n",
      "[stdout:2] /home/jakob/ownCloud/Documents/PhD/Tools/pymofa/tutorial\n",
      "[stdout:3] /home/jakob/ownCloud/Documents/PhD/Tools/pymofa/tutorial\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "import os\n",
    "\n",
    "\n",
    "def find(name, path):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        if name in files:\n",
    "            return root\n",
    "path = find('02_LocalParallelization.ipynb', '/home/')\n",
    "print(path)\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "from ipyparallel import Client\n",
    "c = Client()\n",
    "view = c[:]\n",
    "print(c.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now, to make the code run on all of our engines (and not just on one), the following cells have to start with the [__parallel magic__](https://ipython.org/ipython-doc/3/parallel/magics.html) command *%%px*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] 0\n",
      "[stdout:1] 0\n",
      "[stdout:2] 0\n",
      "[stdout:3] 0\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "from mpi4py import MPI\n",
    "com = MPI.COMM_WORLD\n",
    "print(com.Get_rank())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now, that we have MPI running, and mpi4py recognizing the nodes and their ranks, we can continue with the predator prey exercise, that we know from the first tutorial.\n",
    "\n",
    "First, define the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def predprey_model(prey_birth_rate, prey_mortality, \n",
    "                   predator_efficiency, predator_death_rate,\n",
    "                   initial_prey, initial_predators,\n",
    "                   time_length):\n",
    "    \"\"\"Discrete predetor prey model.\"\"\"\n",
    "    A = -1 * np.ones(time_length)\n",
    "    B = -1 * np.ones(time_length)\n",
    "    A[0] = initial_prey\n",
    "    B[0] = initial_predators\n",
    "    for t in range(1, time_length):\n",
    "        A[t] = A[t-1] + prey_birth_rate * A[t-1] - prey_mortality * B[t-1]*A[t-1]\n",
    "        B[t] = B[t-1] + predator_efficiency * B[t-1]*A[t-1] - predator_death_rate * B[t-1] +\\\n",
    "            0.02 * (0.5 - np.random.rand())\n",
    "    return A, B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Then import the experiment_handling class from pymofa and define a run function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "# imports\n",
    "from pymofa.experiment_handling import experiment_handling as eh\n",
    "import itertools as it\n",
    "import pandas as pd\n",
    "# import cPickle\n",
    "\n",
    "\n",
    "#Definingh the experiment execution function\n",
    "#      it gets paramater you want to investigate, plus `filename` as the last parameter\n",
    "def RUN_FUNC(prey_birth_rate, coupling, predator_death_rate, initial_pop, time_length,\n",
    "             filename):\n",
    "    \"\"\"Insightful docstring.\"\"\"\n",
    "    # poss. process\n",
    "    prey_mortality = coupling\n",
    "    predator_efficiency = coupling\n",
    "    initial_prey = initial_pop\n",
    "    initial_predators = initial_pop\n",
    "    # one could also do more complicated stuff here, e.g. drawing something from a random distribution\n",
    "    \n",
    "    # running the model\n",
    "    preys, predators = predprey_model(prey_birth_rate, prey_mortality, predator_efficiency,\n",
    "                                      predator_death_rate, initial_prey, initial_predators,\n",
    "                                      time_length)\n",
    "    \n",
    "    # preparing the data\n",
    "    res = pd.DataFrame({\"preys\": np.array(preys),\n",
    "                        \"predators\": np.array(predators)})\n",
    "    \n",
    "    # Save Result\n",
    "    res.to_pickle(filename)\n",
    "    \n",
    "    # determine exit status (if something went wrong)\n",
    "    # if exit status > 0 == run passen\n",
    "    # if exit status < 0 == Run Failed\n",
    "    exit_status = 42\n",
    "    \n",
    "    # RUN_FUNC needs to return exit_status\n",
    "    return exit_status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Specify the necessary parameters, generate their combinations and feed them to an experiment handle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "# Path where to Store the simulated Data\n",
    "SAVE_PATH_RAW = \"./dummy/pymofatutorial\"\n",
    "\n",
    "# Parameter combinations to investiage\n",
    "prey_birth_rate = [0.09, 0.1, 0.11]\n",
    "coupling = [0.1]\n",
    "predator_death_rate = [0.005, 0.01, 0.05, 0.1]\n",
    "initial_pop = [1.0, 2.0]\n",
    "time_length = [1000]\n",
    "\n",
    "PARAM_COMBS = list(it.product(prey_birth_rate, coupling, predator_death_rate, initial_pop, time_length))\n",
    "\n",
    "# Sample Size\n",
    "SAMPLE_SIZE = 5\n",
    "\n",
    "# INDEX \n",
    "INDEX = {i: RUN_FUNC.__code__.co_varnames[i] for i in range(RUN_FUNC.__code__.co_argcount-1)}\n",
    "\n",
    "# initiate handle instance with experiment variables\n",
    "handle = eh(SAMPLE_SIZE, PARAM_COMBS, INDEX, SAVE_PATH_RAW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally run the model - now in parallel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "120 of 120 single computations left\n",
      "Only one node available. No parallel execution.\n",
      "Splitting calculations to 0 nodes.\n",
      "Calculating 0 ...done.\n",
      "[stdout:1] \n",
      "120 of 120 single computations left\n",
      "Only one node available. No parallel execution.\n",
      "Splitting calculations to 0 nodes.\n",
      "Calculating 0 ...done.\n",
      "[stdout:2] \n",
      "120 of 120 single computations left\n",
      "Only one node available. No parallel execution.\n",
      "Splitting calculations to 0 nodes.\n",
      "Calculating 0 ...done.\n",
      "[stdout:3] \n",
      "120 of 120 single computations left\n",
      "Only one node available. No parallel execution.\n",
      "Splitting calculations to 0 nodes.\n",
      "Calculating 0 ...done.\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "# Compute experiemnts raw data\n",
    "handle.compute(RUN_FUNC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if everyting whent well, the calculations should have been splitted between all the engines that you've started in the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run you experiments in scripts outside of an IPython notebook, simply run you experiment script (defining a run function, an experiment handle and calling the compute routine of that handle) with mpirun in a terminal "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}